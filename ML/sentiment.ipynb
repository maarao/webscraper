{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from textblob import Word\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from keras.models import Sequential\n",
    "from tokenizers import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", text)\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text.lower())\n",
    "\n",
    "    words = [word for word in words if word not in string.punctuation]\n",
    "\n",
    "    # Remove stop words\n",
    "    words = \" \".join([word for word in words if word.isalpha()]).lower()    \n",
    "        \n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.theonion.com/nickelodeon-announces-dan-schneider-has-been-chemically-1851370242\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "parsed_url = urlparse(url).netloc\n",
    "base_url = parsed_url[4:]\n",
    "\n",
    "text = []\n",
    "# Find all <p> elements and print their text\n",
    "for paragraph in soup.find_all('p'):\n",
    "    text.append(preprocess_text(paragraph.get_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['los angeles saying the channel would do everything in its power to make up for the writer and producer s years of toxic abusive behavior nickelodeon announced thursday that dan schneider had been chemically castrated with slime while in his powerful position at nickelodeon mr schneider harassed child stars and cast them in sexualized scenes which is why we have elected to sterilize him with a toxic dosage of neon green slime said ceo brian robbins adding that the creator of drake josh icarly and sam cat had been tied up and had a large vat of the viscous liquid poured over his body until his testicles shriveled up and his penis fell off we sincerely regret allowing dan to spend years preying on those less powerful than him and now that the slime has permanently mangled his genitals we are confident he will never do so again rest assured the procedure was incredibly painful he will not make the same mistake again at press time nickelodeon added that schneider would be forced to carry around a lever and douse himself in slime every six months to ensure that his urges would never return']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [phrase for phrase in text if phrase.count(' ') > 2]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob: Determining Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_score = []\n",
    "\n",
    "for phrase in text:\n",
    "    polarity_score.append(TextBlob(phrase).sentiment.polarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### polarity denotes the sentiment of text. values lie in [-1,1]. -1 denotes a highly negative sentiment and 1 denotes a hightly positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_min = min(polarity_score)\n",
    "polarity_max = max(polarity_score)\n",
    "polarity_std = np.std(polarity_score)\n",
    "polarity_mean = np.mean(polarity_score)\n",
    "polarity_range = polarity_max - polarity_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  0.04476190476190476\n",
      "Max:  0.04476190476190476\n",
      "Standard Deviation:  0.0\n",
      "Mean:  0.04476190476190476\n",
      "Range:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Min: \",polarity_min)\n",
    "print(\"Max: \",polarity_max)\n",
    "print(\"Standard Deviation: \", polarity_std)\n",
    "print(\"Mean: \", polarity_mean)\n",
    "print(\"Range: \",polarity_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob: Subjectivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity_score = []\n",
    "\n",
    "for phrase in text:\n",
    "    subjectivity_score.append(TextBlob(phrase).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subjectivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity_min = min(subjectivity_score)\n",
    "subjectivity_max = max(subjectivity_score)\n",
    "subjectivity_std = np.std(subjectivity_score)\n",
    "subjectivity_mean = np.mean(subjectivity_score)\n",
    "subjectivity_range = subjectivity_max - subjectivity_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  0.535357142857143\n",
      "Max:  0.535357142857143\n",
      "Standard Deviation:  0.0\n",
      "median:  0.535357142857143\n",
      "Mean:  0.535357142857143\n",
      "Range:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Min: \",subjectivity_min)\n",
    "print(\"Max: \",subjectivity_max)\n",
    "print(\"Standard Deviation: \", subjectivity_std)\n",
    "print(\"median: \", np.median(subjectivity_score))\n",
    "print(\"Mean: \", subjectivity_mean)\n",
    "print(\"Range: \",subjectivity_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17284</td>\n",
       "      <td>Rift Between Officers and Residents as Killing...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Benjamin Mueller and Al Baker</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17285</td>\n",
       "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Margalit Fox</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17286</td>\n",
       "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>William McDonald</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17287</td>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Choe Sang-Hun</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>53287</td>\n",
       "      <td>73465</td>\n",
       "      <td>Rex Tillerson Says Climate Change Is Real, but …</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Robinson Meyer</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As chairman and CEO of ExxonMobil, Rex Tillers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>53288</td>\n",
       "      <td>73466</td>\n",
       "      <td>The Biggest Intelligence Questions Raised by t...</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Amy Zegart</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I’ve spent nearly 20 years looking at intellig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>53289</td>\n",
       "      <td>73467</td>\n",
       "      <td>Trump Announces Plan That Does Little to Resol...</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Jeremy Venook</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Donald Trump will not be taking necessary st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>53290</td>\n",
       "      <td>73468</td>\n",
       "      <td>Dozens of For-Profit Colleges Could Soon Close</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Emily DeRuy</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dozens of   colleges could be forced to close ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>53291</td>\n",
       "      <td>73469</td>\n",
       "      <td>The Milky Way’s Stolen Stars</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Marina Koren</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The force of gravity can be described using a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                              title  \\\n",
       "0               0  17283  House Republicans Fret About Winning Their Hea...   \n",
       "1               1  17284  Rift Between Officers and Residents as Killing...   \n",
       "2               2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...   \n",
       "3               3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
       "4               4  17287  Kim Jong-un Says North Korea Is Preparing to T...   \n",
       "...           ...    ...                                                ...   \n",
       "49995       53287  73465   Rex Tillerson Says Climate Change Is Real, but …   \n",
       "49996       53288  73466  The Biggest Intelligence Questions Raised by t...   \n",
       "49997       53289  73467  Trump Announces Plan That Does Little to Resol...   \n",
       "49998       53290  73468    Dozens of For-Profit Colleges Could Soon Close    \n",
       "49999       53291  73469                       The Milky Way’s Stolen Stars   \n",
       "\n",
       "          publication                         author        date    year  \\\n",
       "0      New York Times                     Carl Hulse  2016-12-31  2016.0   \n",
       "1      New York Times  Benjamin Mueller and Al Baker  2017-06-19  2017.0   \n",
       "2      New York Times                   Margalit Fox  2017-01-06  2017.0   \n",
       "3      New York Times               William McDonald  2017-04-10  2017.0   \n",
       "4      New York Times                  Choe Sang-Hun  2017-01-02  2017.0   \n",
       "...               ...                            ...         ...     ...   \n",
       "49995        Atlantic                 Robinson Meyer  2017-01-11  2017.0   \n",
       "49996        Atlantic                     Amy Zegart  2017-01-11  2017.0   \n",
       "49997        Atlantic                  Jeremy Venook  2017-01-11  2017.0   \n",
       "49998        Atlantic                    Emily DeRuy  2017-01-11  2017.0   \n",
       "49999        Atlantic                   Marina Koren  2017-01-11  2017.0   \n",
       "\n",
       "       month  url                                            content  \n",
       "0       12.0  NaN  WASHINGTON  —   Congressional Republicans have...  \n",
       "1        6.0  NaN  After the bullet shells get counted, the blood...  \n",
       "2        1.0  NaN  When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
       "3        4.0  NaN  Death may be the great equalizer, but it isn’t...  \n",
       "4        1.0  NaN  SEOUL, South Korea  —   North Korea’s leader, ...  \n",
       "...      ...  ...                                                ...  \n",
       "49995    1.0  NaN  As chairman and CEO of ExxonMobil, Rex Tillers...  \n",
       "49996    1.0  NaN  I’ve spent nearly 20 years looking at intellig...  \n",
       "49997    1.0  NaN    Donald Trump will not be taking necessary st...  \n",
       "49998    1.0  NaN  Dozens of   colleges could be forced to close ...  \n",
       "49999    1.0  NaN  The force of gravity can be described using a ...  \n",
       "\n",
       "[50000 rows x 10 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/articles.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze sentiment and return sentiment label\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    \n",
    "    if polarity > 0.10316472712094597:\n",
    "        return 'positive'\n",
    "    elif polarity < 0.03997114079477093:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply sentiment analysis function to the 'content' column and create a new 'sentiment' column\n",
    "df['sentiment'] = df['content'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03997114079477093\n",
      "0.10316472712094597\n"
     ]
    }
   ],
   "source": [
    "# text = np.array(df['content'])\n",
    "\n",
    "# polarity_score = []\n",
    "\n",
    "# for phrase in text:\n",
    "#     polarity_score.append(TextBlob(phrase).sentiment.polarity)\n",
    "\n",
    "tlow = np.percentile(polarity_score, 33)\n",
    "thigh = np.percentile(polarity_score, 66)\n",
    "print(tlow)\n",
    "print(thigh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    16500\n",
       "neutral     16500\n",
       "positive    17000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment')['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df, stop_words):\n",
    "    df['content'] = df['content'].apply(lambda x: ' '.join(x.lower() for x in x.split()))\n",
    "    # Replacing the digits/numbers\n",
    "    df['content'] = df['content'].str.replace('d', '')\n",
    "    # Removing stop words\n",
    "    df['content'] = df['content'].apply(lambda x: ' '.join(x for x in x.split() if x not in stop_words))\n",
    "    # Lemmatization\n",
    "    df['content'] = df['content'].apply(lambda x: ' '.join([Word(x).lemmatize() for x in x.split()]))\n",
    "    return df\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "data_cleaned = cleaning(df, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>washington — congressional republican new fear...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bullet shell get counte, bloo ries votive canl...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>walt isney’s “bambi” opene 1942, critic praise...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eath may great equalizer, isn’t necessarily ev...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seoul, south korea — north korea’s leaer, kim ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>chairman ceo exxonmobil, rex tillerson amitte ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>i’ve spent nearly 20 year looking intelligence...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>onal trump taking necessary step resolve confl...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>ozens college coul force close next several ye...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>force gravity escribe using number metaphors: ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content sentiment\n",
       "0      washington — congressional republican new fear...  negative\n",
       "1      bullet shell get counte, bloo ries votive canl...  negative\n",
       "2      walt isney’s “bambi” opene 1942, critic praise...   neutral\n",
       "3      eath may great equalizer, isn’t necessarily ev...  positive\n",
       "4      seoul, south korea — north korea’s leaer, kim ...  positive\n",
       "...                                                  ...       ...\n",
       "49995  chairman ceo exxonmobil, rex tillerson amitte ...   neutral\n",
       "49996  i’ve spent nearly 20 year looking intelligence...   neutral\n",
       "49997  onal trump taking necessary step resolve confl...   neutral\n",
       "49998  ozens college coul force close next several ye...  positive\n",
       "49999  force gravity escribe using number metaphors: ...   neutral\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned[['content', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simon\\Anaconda\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 155343)\t1\n",
      "  (0, 33673)\t3\n",
      "  (0, 119078)\t16\n",
      "  (0, 97437)\t2\n",
      "  (0, 46616)\t1\n",
      "  (0, 32731)\t3\n",
      "  (0, 59503)\t11\n",
      "  (0, 26645)\t8\n",
      "  (0, 79959)\t2\n",
      "  (0, 100450)\t5\n",
      "  (0, 9149)\t13\n",
      "  (0, 157368)\t1\n",
      "  (0, 66034)\t1\n",
      "  (0, 146670)\t9\n",
      "  (0, 35254)\t8\n",
      "  (0, 30051)\t2\n",
      "  (0, 82922)\t1\n",
      "  (0, 38858)\t1\n",
      "  (0, 44730)\t5\n",
      "  (0, 22754)\t5\n",
      "  (0, 137845)\t2\n",
      "  (0, 28561)\t1\n",
      "  (0, 123404)\t7\n",
      "  (0, 14085)\t2\n",
      "  (0, 134193)\t1\n",
      "  :\t:\n",
      "  (49999, 13254)\t2\n",
      "  (49999, 143006)\t1\n",
      "  (49999, 69076)\t1\n",
      "  (49999, 116226)\t1\n",
      "  (49999, 82639)\t1\n",
      "  (49999, 102662)\t1\n",
      "  (49999, 141589)\t1\n",
      "  (49999, 68421)\t1\n",
      "  (49999, 155163)\t1\n",
      "  (49999, 89934)\t1\n",
      "  (49999, 46247)\t1\n",
      "  (49999, 51493)\t13\n",
      "  (49999, 29698)\t1\n",
      "  (49999, 134339)\t1\n",
      "  (49999, 90916)\t6\n",
      "  (49999, 152652)\t1\n",
      "  (49999, 67501)\t1\n",
      "  (49999, 25665)\t1\n",
      "  (49999, 84693)\t2\n",
      "  (49999, 55660)\t2\n",
      "  (49999, 131916)\t1\n",
      "  (49999, 150132)\t1\n",
      "  (49999, 130878)\t1\n",
      "  (49999, 123768)\t5\n",
      "  (49999, 51492)\t1\n",
      "Accuracuy Score:  0.53304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(df['content'])\n",
    "print(text_counts)\n",
    "#Splitting the data into trainig and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, df['sentiment'], test_size=0.25, random_state=5)\n",
    "#Training the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)\n",
    "#Caluclating the accuracy score of the model\n",
    "from sklearn import metrics\n",
    "predicted = MNB.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, Y_test)\n",
    "print(\"Accuracuy Score: \",accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.53312\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Tokenizer with alphanumeric pattern\n",
    "token = RegexpTokenizer(r'\\b[A-Za-z0-9]+\\b')\n",
    "\n",
    "# Custom function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Tokenize and remove stopwords and punctuation\n",
    "    tokens = token.tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in stop_words and token not in string.punctuation]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to 'content' column\n",
    "df['cleaned_content'] = df['content'].apply(preprocess_text)\n",
    "\n",
    "# Vectorize text using CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1, 1))  # You can adjust ngram_range as needed\n",
    "text_counts = cv.fit_transform(df['cleaned_content'])\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_counts, df['sentiment'], test_size=0.25, random_state=2)\n",
    "\n",
    "# Training the Multinomial Naive Bayes model\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "predicted = mnb.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, y_test)\n",
    "print(\"Accuracy Score:\", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
