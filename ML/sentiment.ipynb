{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from textblob import Word\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from keras.models import Sequential\n",
    "from tokenizers import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", text)\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text.lower())\n",
    "\n",
    "    words = [word for word in words if word not in string.punctuation]\n",
    "\n",
    "    # Remove stop words\n",
    "    words = \" \".join([word for word in words if word.isalpha()]).lower()    \n",
    "        \n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.nbcnews.com/politics/2024-election/biden-rakes-25-million-new-york-fundraiser-obama-clinton-rcna145534\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "parsed_url = urlparse(url).netloc\n",
    "base_url = parsed_url[4:]\n",
    "\n",
    "text = []\n",
    "# Find all <p> elements and print their text\n",
    "for paragraph in soup.find_all('p'):\n",
    "    text.append(preprocess_text(paragraph.get_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there are no new alerts at this time',\n",
       " 'president joe biden was joined thursday by two of his democratic predecessors for a star studded fundraiser at radio city music hall that his campaign said brought in more than million',\n",
       " 'former presidents barack obama and bill clinton participated in the event in new york with more than supporters in attendance including several protesters who interrupted the program when the three presidents were speaking',\n",
       " 'actor and comedian mindy kaling hosted the program which ended at around p m and late night host stephen colbert moderated a conversation with biden clinton and obama special guests include celebrities like queen latifah lizzo ben platt cynthia erivo and lea michele',\n",
       " 'during the nearly hourlong moderated conversation colbert joked that the moment was historic because three presidents have come to new york and not one of them to appear in court taking a jab at former president donald trump s criminal indictments and civil trials',\n",
       " 'clinton also took a swipe at trump the presumptive gop nominee arguing that he had a good couple of years because he stole them from barack obama',\n",
       " 'but the discussion was interrupted at least five times by protesters colbert acknowledged one protester and asked biden about the u s role in ensuring a peaceful and prosperous future for both israelis and palestinians',\n",
       " 'biden said more needed to be done to get relief into gaza but added that israel s very existence was at stake',\n",
       " 'there has to be a train for a two state solution biden said it doesn t have to carry today there has to be a progression and i think we can do that',\n",
       " 'his response was met with a standing ovation and chants of four more years',\n",
       " 'obama sternly addressed a protester when he was interrupted saying you can t just talk and not listen',\n",
       " 'that s part of democracy obama added part of democracy is not just talking it s listening that s what the other side does and it is important for us to understand that it is possible to have moral clarity and have deeply held beliefs but still recognize that the world is complicated and it is hard to solve these problems',\n",
       " 'the crowd erupted in applause',\n",
       " 'biden s team has taken steps to minimize disruptions including making events smaller and withholding exact locations longer than usual after a speech in january when pro palestinian protesters interrupted him about a dozen times',\n",
       " 'outside the new york venue thursday more than pro palestinian protesters chanted slogans like biden biden you re a liar and waved palestinian flags and signs with anti war messages',\n",
       " 'the group abandon biden encouraged people to protest the president during his visit over the white house s handling of the israel hamas war',\n",
       " 'we can not idly sit by as our president aides and abets genocide in gaza the group s new york co chair mosaab sadia said in a statement the movement to abandon biden is only just beginning',\n",
       " 'inside radio city music hall the novelty of having three presidents in the same room was not lost on attendees',\n",
       " 'earlier in the program kaling joked about having biden obama and clinton in the same room saying that when someone shouts mr president three people turn around',\n",
       " 'ticket prices started at but the largest contributions shot up to half a million dollars some of the biggest donors were to have their pictures taken with all three presidents by photographer annie leibovitz',\n",
       " 'first lady jill biden called the program the fundraiser to end all fundraisers',\n",
       " 'house minority leader hakeem jeffries d n y and senate majority leader chuck schumer d n y also delivered remarks',\n",
       " 'for the three presidents the fundraiser capped off a day of mobilization efforts that included sitting for an interview with the podcast smartless which the white house said would be available at a later unspecified date',\n",
       " 'they also sat for a discussion with biden s campaign manager julie chavez rodriguez which was streamed to grassroots donors the presidents talked about re election efforts both clinton and obama served two terms as well as lighter topics like favorite ice cream favors',\n",
       " 'you re all part of an incredible team we re building and we re just getting started biden said in his closing message during the discussion so let s keep going let s win this november',\n",
       " 'the trio arrived at radio city music hall together in the beast the president s car in the motorcade',\n",
       " 'biden also invited obama to ride in the beast after he landed at john f kennedy international airport where they enjoyed catching up on their personal and professional lives an aide to obama told nbc news',\n",
       " 'the show of unity among biden clinton and obama stands in stark contrast to trump who faces opposition from members of his own administration including former vice president mike pence as he seeks a return to the white house in november',\n",
       " 'former president george w bush the only other republican former president declined to support trump in',\n",
       " 'the trump campaign has not held a major event since march earlier thursday trump attended the wake for a new york police officer who was shot and killed in queens on monday',\n",
       " 'biden and trump are polling neck and neck with of voters supporting trump and supporting biden according to a march poll by cnbc that poll however had trump leading biden by percentage points when respondents were asked which candidate was the best on economic issues',\n",
       " 'during thursday s moderated discussion colbert asked clinton what he would say to voters who do not feel like the economy is strong clinton answered that the recession and covid are still affecting voters and that trump did not sustain economic growth spurred by obama biden and vice president kamala harris have methodically put humpty dumpty back together again clinton said',\n",
       " 'we should not make s mistake again he added referring to when trump defeated his wife former secretary of state hillary clinton',\n",
       " 'mike memoli is an nbc news correspondent',\n",
       " 'megan lebowitz is a politics reporter for nbc news']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [phrase for phrase in text if phrase.count(' ') > 2]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob: Determining Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_score = []\n",
    "\n",
    "for phrase in text:\n",
    "    polarity_score.append(TextBlob(phrase).sentiment.polarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### polarity denotes the sentiment of text. values lie in [-1,1]. -1 denotes a highly negative sentiment and 1 denotes a hightly positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_min = min(polarity_score)\n",
    "polarity_max = max(polarity_score)\n",
    "polarity_std = np.std(polarity_score)\n",
    "polarity_mean = np.mean(polarity_score)\n",
    "polarity_range = polarity_max - polarity_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  -0.16666666666666666\n",
      "Max:  0.8500000000000001\n",
      "Standard Deviation:  0.23332012715639822\n",
      "Mean:  0.13822353638425067\n",
      "Range:  1.0166666666666668\n"
     ]
    }
   ],
   "source": [
    "print(\"Min: \",polarity_min)\n",
    "print(\"Max: \",polarity_max)\n",
    "print(\"Standard Deviation: \", polarity_std)\n",
    "print(\"Mean: \", polarity_mean)\n",
    "print(\"Range: \",polarity_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob: Subjectivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity_score = []\n",
    "\n",
    "for phrase in text:\n",
    "    subjectivity_score.append(TextBlob(phrase).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subjectivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity_min = min(subjectivity_score)\n",
    "subjectivity_max = max(subjectivity_score)\n",
    "subjectivity_std = np.std(subjectivity_score)\n",
    "subjectivity_mean = np.mean(subjectivity_score)\n",
    "subjectivity_range = subjectivity_max - subjectivity_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  0.0\n",
      "Max:  1.0\n",
      "Standard Deviation:  0.2465389450238324\n",
      "median:  0.3333333333333333\n",
      "Mean:  0.30681823335394764\n",
      "Range:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Min: \",subjectivity_min)\n",
    "print(\"Max: \",subjectivity_max)\n",
    "print(\"Standard Deviation: \", subjectivity_std)\n",
    "print(\"median: \", np.median(subjectivity_score))\n",
    "print(\"Mean: \", subjectivity_mean)\n",
    "print(\"Range: \",subjectivity_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/articles1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_array = df['content'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_score = []\n",
    "\n",
    "for phrase in content_array:\n",
    "    polarity_score.append(TextBlob(phrase).sentiment.polarity)\n",
    "\n",
    "# polarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03997114079477093\n",
      "0.10316472712094597\n"
     ]
    }
   ],
   "source": [
    "tlow = np.percentile(polarity_score, 33)\n",
    "thigh = np.percentile(polarity_score, 66)\n",
    "print(tlow)\n",
    "print(thigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze sentiment and return sentiment label\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    \n",
    "    if polarity > thigh:\n",
    "        return 2\n",
    "    elif polarity < tlow:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Apply sentiment analysis function to the 'content' column and create a new 'sentiment' column\n",
    "df['sentiment'] = df['content'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    16500\n",
       "1    16500\n",
       "2    17000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment')['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df, stop_words):\n",
    "    df['content'] = df['content'].apply(lambda x: ' '.join(x.lower() for x in x.split()))\n",
    "    # Replacing the digits/numbers\n",
    "    df['content'] = df['content'].str.replace('d', '')\n",
    "    # Removing stop words\n",
    "    df['content'] = df['content'].apply(lambda x: ' '.join(x for x in x.split() if x not in stop_words))\n",
    "    # Lemmatization\n",
    "    #df['content'] = df['content'].apply(lambda x: ' '.join([Word(x).lemmatize() for x in x.split()]))\n",
    "    return df\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "data_cleaned = cleaning(df, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>washington — congressional republicans new fea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17284</td>\n",
       "      <td>Rift Between Officers and Residents as Killing...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Benjamin Mueller and Al Baker</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bullet shells get counte, bloo ries votive can...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17285</td>\n",
       "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Margalit Fox</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walt isney’s “bambi” opene 1942, critics prais...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17286</td>\n",
       "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>William McDonald</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eath may great equalizer, isn’t necessarily ev...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17287</td>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Choe Sang-Hun</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seoul, south korea — north korea’s leaer, kim ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>53287</td>\n",
       "      <td>73465</td>\n",
       "      <td>Rex Tillerson Says Climate Change Is Real, but …</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Robinson Meyer</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chairman ceo exxonmobil, rex tillerson amitte ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>53288</td>\n",
       "      <td>73466</td>\n",
       "      <td>The Biggest Intelligence Questions Raised by t...</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Amy Zegart</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i’ve spent nearly 20 years looking intelligenc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>53289</td>\n",
       "      <td>73467</td>\n",
       "      <td>Trump Announces Plan That Does Little to Resol...</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Jeremy Venook</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>onal trump taking necessary steps resolve conf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>53290</td>\n",
       "      <td>73468</td>\n",
       "      <td>Dozens of For-Profit Colleges Could Soon Close</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Emily DeRuy</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ozens colleges coul force close next several y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>53291</td>\n",
       "      <td>73469</td>\n",
       "      <td>The Milky Way’s Stolen Stars</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Marina Koren</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>force gravity escribe using number metaphors: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                              title  \\\n",
       "0               0  17283  House Republicans Fret About Winning Their Hea...   \n",
       "1               1  17284  Rift Between Officers and Residents as Killing...   \n",
       "2               2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...   \n",
       "3               3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
       "4               4  17287  Kim Jong-un Says North Korea Is Preparing to T...   \n",
       "...           ...    ...                                                ...   \n",
       "49995       53287  73465   Rex Tillerson Says Climate Change Is Real, but …   \n",
       "49996       53288  73466  The Biggest Intelligence Questions Raised by t...   \n",
       "49997       53289  73467  Trump Announces Plan That Does Little to Resol...   \n",
       "49998       53290  73468    Dozens of For-Profit Colleges Could Soon Close    \n",
       "49999       53291  73469                       The Milky Way’s Stolen Stars   \n",
       "\n",
       "          publication                         author        date    year  \\\n",
       "0      New York Times                     Carl Hulse  2016-12-31  2016.0   \n",
       "1      New York Times  Benjamin Mueller and Al Baker  2017-06-19  2017.0   \n",
       "2      New York Times                   Margalit Fox  2017-01-06  2017.0   \n",
       "3      New York Times               William McDonald  2017-04-10  2017.0   \n",
       "4      New York Times                  Choe Sang-Hun  2017-01-02  2017.0   \n",
       "...               ...                            ...         ...     ...   \n",
       "49995        Atlantic                 Robinson Meyer  2017-01-11  2017.0   \n",
       "49996        Atlantic                     Amy Zegart  2017-01-11  2017.0   \n",
       "49997        Atlantic                  Jeremy Venook  2017-01-11  2017.0   \n",
       "49998        Atlantic                    Emily DeRuy  2017-01-11  2017.0   \n",
       "49999        Atlantic                   Marina Koren  2017-01-11  2017.0   \n",
       "\n",
       "       month  url                                            content  \\\n",
       "0       12.0  NaN  washington — congressional republicans new fea...   \n",
       "1        6.0  NaN  bullet shells get counte, bloo ries votive can...   \n",
       "2        1.0  NaN  walt isney’s “bambi” opene 1942, critics prais...   \n",
       "3        4.0  NaN  eath may great equalizer, isn’t necessarily ev...   \n",
       "4        1.0  NaN  seoul, south korea — north korea’s leaer, kim ...   \n",
       "...      ...  ...                                                ...   \n",
       "49995    1.0  NaN  chairman ceo exxonmobil, rex tillerson amitte ...   \n",
       "49996    1.0  NaN  i’ve spent nearly 20 years looking intelligenc...   \n",
       "49997    1.0  NaN  onal trump taking necessary steps resolve conf...   \n",
       "49998    1.0  NaN  ozens colleges coul force close next several y...   \n",
       "49999    1.0  NaN  force gravity escribe using number metaphors: ...   \n",
       "\n",
       "       sentiment  \n",
       "0              0  \n",
       "1              0  \n",
       "2              1  \n",
       "3              2  \n",
       "4              2  \n",
       "...          ...  \n",
       "49995          1  \n",
       "49996          1  \n",
       "49997          1  \n",
       "49998          2  \n",
       "49999          1  \n",
       "\n",
       "[50000 rows x 11 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.to_csv('./data/articles2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./data/articles2.csv\")\n",
    "df1 = cleaning(df, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\simon\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\simon\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\simon\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\index.pyx:155\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'content'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      8\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m x\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mfit_transform(df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(x, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\simon\\Anaconda\\Lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\simon\\Anaconda\\Lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\simon\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'content'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "x=vectorizer.fit_transform(df1['content'])\n",
    "\n",
    "y = df1['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "mnb_classifier = MultinomialNB()\n",
    "mnb_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mnb_classifier.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4\n"
     ]
    }
   ],
   "source": [
    "vector_x = vectorizer.transform(text)\n",
    "predictions = mnb_classifier.predict(vector_x)\n",
    "\n",
    "sentiment_map = {0:'negative',1:'neutral',2:'positive'}\n",
    "predicted_sentiments = [sentiment_map[pred] for pred in predictions]\n",
    "\n",
    "print(predictions.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
